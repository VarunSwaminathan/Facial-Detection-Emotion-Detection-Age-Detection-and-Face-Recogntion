# -*- coding: utf-8 -*-
"""feature.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sJynCyj__813qS71T6CkJPoLc3SXBhdJ
"""

import numpy as np
import cv2
import deepface
from deepface import DeepFace

from google.colab import files
uploaded = files.upload()
image = cv2.imread('count_faces.jpg')

embedding_objs = DeepFace.represent(image)

print((embedding_objs[0]))

dataset_path = './sample_data/'

import pandas 
image_data = pandas.read_csv("congress.csv", encoding="Latin-1")

from google.colab import drive
drive.mount('/content/drive')

import os


img_pth = dataset_path+'img/' + k[0]
print(img_pth)
k = cv2.imread(img_pth)
print(k)

import os
from PIL import Image
embeddings = {}
# /content/drive/MyDrive/dataset/img/a000370_200.jpg
# /content/drive/MyDrive/dataset/img/a000370_200.jpg /content/drive/MyDrive/dataset/img/a000370_200.jpg
for _,rows in image_data.iterrows():
    k = './sample_data/'
    image_path = k + rows['img'].strip()
    print(image_path)
    images = cv2.imread(image_path)
    print(images)

    embeddings[rows['name']] = DeepFace.represent(images, enforce_detection=False)

import json
  
emb_jb = json.dumps(embeddings)

with open("embwddings.json", "w") as out:
  out.write(emb_jb)

faceDetect = cv2.CascadeClassifier(cv2.data.haarcascades  + "haarcascade_frontalface_default.xml")
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

faces = faceDetect.detectMultiScale(gray_image, 1.2, 5)

uploaded = files.upload()

emd_pth = "/content/embeddings.json"

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

face_recognizer = cv2.face.LBPHFaceRecognizer_create()
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades  + "haarcascade_frontalface_default.xml")
faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

f = open('embeddings.json')
file = json.load(f)

face_features = []
for (x, y, w, h) in faces:
    face_gray = gray[y:y+h, x:x+w]
    features = DeepFace.represent(image)
    d = {k:np.dot(np.array(v),features)/(np.norm(v)*np.norm(features)) for k,v in file.items()}
    name = max(d, key=d.get)

    # lbp = cv2.face.LBPHFaceRecognizer_create()
    # hist = cv2.calcHist([face_gray], [0], None, [256], [0, 256])
    # cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)
    # face_features.append(hist)

cosine = (features, values) 
{k:cosine for k,v in embeddings.items()}
# for i in range(len(face_features)):
#     for j in range(len(face_features)):
        similarity = cv2.compareHist(face_features[i], face_features[j], cv2.HISTCMP_CORREL)
        
        if cosine > 0.8:
            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(image, embeddings[rows['name']], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

